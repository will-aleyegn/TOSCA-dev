# VmbPy API Documentation

## Overview

VmbPy is a Python API for Allied Vision cameras, providing a comprehensive set of classes and methods to control camera hardware, capture images, and process frame data. This document serves as a complete reference guide for programming with the VmbPy API.

## Core Components

VmbPy's architecture consists of several main components:

- **VmbSystem**: The entry point to the entire system
- **TransportLayer**: Represents different transport technologies
- **Interface**: Represents physical interfaces
- **Camera**: Provides access to camera devices
- **Stream**: Handles data streams from cameras
- **LocalDevice**: Provides access to local device features
- **Frame**: Represents an image frame
- **Feature**: Various feature types to control camera parameters
- **Error**: Different error types for exception handling

## 1. VmbSystem

The `VmbSystem` class is the entry point to the API, implemented as a singleton.

### Basic Usage

```python
import vmbpy

# Get the VmbSystem singleton instance
with vmbpy.VmbSystem.get_instance() as vmb:
    # Use the system within this context
    cameras = vmb.get_all_cameras()
```

### Key Methods

- `get_instance()`: Get the singleton instance
- `get_all_cameras()`: Get all available cameras
- `get_camera_by_id(id_)`: Find a specific camera
- `get_all_interfaces()`: Get all interfaces
- `get_all_transport_layers()`: Get all transport layers
- `get_version()`: Get API version
- `register_camera_change_handler(handler)`: Register callback for camera events
- `register_interface_change_handler(handler)`: Register callback for interface events

## 2. Camera

The `Camera` class represents a physical camera device and is the primary interface for image acquisition.

### Basic Usage

```python
import vmbpy

with vmbpy.VmbSystem.get_instance() as vmb:
    cameras = vmb.get_all_cameras()
    
    if cameras:
        with cameras[0] as cam:
            # Use the camera
            model = cam.get_model()
            print(f"Using camera model: {model}")
            
            # Configure camera
            cam.set_pixel_format(vmbpy.PixelFormat.Mono8)
            
            # Get a single frame
            frame = cam.get_frame()
```

### Key Methods

- **Information Methods**
  - `get_id()`: Get camera ID
  - `get_name()`: Get camera name
  - `get_model()`: Get camera model
  - `get_serial()`: Get camera serial number
  - `get_interface()`: Get camera interface
  - `get_transport_layer()`: Get camera transport layer

- **Feature Access**
  - `get_all_features()`: Get all features
  - `get_feature_by_name(feat_name)`: Get a specific feature
  - `get_features_by_category(category)`: Get features by category
  - `get_features_by_type(feat_type)`: Get features by type

- **Image Acquisition**
  - `get_pixel_format()`: Get current pixel format
  - `set_pixel_format(fmt)`: Set pixel format
  - `get_frame(timeout_ms=2000)`: Get a single frame (synchronous)
  - `get_frame_generator(limit=None, timeout_ms=2000)`: Generate frames one by one
  - `get_frame_with_context(timeout_ms=2000)`: Get a frame for use in a context
  - `start_streaming(handler, buffer_count=5)`: Start asynchronous streaming
  - `stop_streaming()`: Stop streaming
  - `queue_frame(frame)`: Return a frame to the queue in streaming mode
  - `is_streaming()`: Check if camera is streaming

- **Settings Management**
  - `load_settings(file_path)`: Load settings from XML file
  - `save_settings(file_path)`: Save settings to XML file

- **Access Mode**
  - `get_access_mode()`: Get current access mode
  - `set_access_mode(access_mode)`: Set access mode
  - `get_permitted_access_modes()`: Get all permitted access modes

- **Memory Access**
  - `read_memory(addr, max_bytes)`: Read from camera memory
  - `write_memory(addr, data)`: Write to camera memory

## 3. Frame

The `Frame` class represents an image frame acquired from a camera.

### Basic Usage

```python
import vmbpy
import numpy as np
import cv2

with vmbpy.VmbSystem.get_instance() as vmb:
    with vmb.get_all_cameras()[0] as cam:
        frame = cam.get_frame()
        
        # Convert to numpy array for processing
        image = frame.as_numpy_ndarray()
        
        # Get frame metadata
        width = frame.get_width()
        height = frame.get_height()
        pixel_format = frame.get_pixel_format()
        
        # Convert to a different format if needed
        if pixel_format != vmbpy.PixelFormat.Bgr8:
            frame = frame.convert_pixel_format(vmbpy.PixelFormat.Bgr8)
            
        # Use with OpenCV
        opencv_image = frame.as_opencv_image()
        cv2.imshow("Camera Image", opencv_image)
        cv2.waitKey(0)
```

### Key Methods

- **Data Access**
  - `get_buffer()`: Get internal buffer object
  - `get_buffer_size()`: Get buffer size in bytes
  - `as_numpy_ndarray()`: Convert to NumPy array
  - `as_opencv_image()`: Convert to OpenCV-compatible image
  - `convert_pixel_format(target_fmt)`: Convert to different pixel format

- **Metadata**
  - `get_width()`: Get image width
  - `get_height()`: Get image height
  - `get_offset_x()`: Get horizontal offset
  - `get_offset_y()`: Get vertical offset
  - `get_pixel_format()`: Get pixel format
  - `get_id()`: Get frame ID
  - `get_timestamp()`: Get frame timestamp
  - `get_status()`: Get frame status

- **Chunk Data**
  - `contains_chunk_data()`: Check if frame contains chunk data
  - `access_chunk_data(callback)`: Access chunk data via callback

## 4. Feature Types

Features are used to control camera parameters. There are different feature types:

- `IntFeature`: Integer values
- `FloatFeature`: Floating-point values
- `BoolFeature`: Boolean values
- `StringFeature`: String values
- `EnumFeature`: Enumeration values
- `CommandFeature`: Command execution
- `RawFeature`: Raw byte sequences

### Common Feature Methods

All feature types share these methods:

- `get()`: Get current value
- `set(val)`: Set value
- `get_name()`: Get feature name
- `get_display_name()`: Get display name
- `get_description()`: Get description
- `get_tooltip()`: Get tooltip
- `get_category()`: Get category
- `get_visibility()`: Get UI visibility level
- `get_access_mode()`: Get access mode
- `is_readable()`: Check if readable
- `is_writeable()`: Check if writeable
- `register_change_handler(handler)`: Register callback for value changes

### Specific Feature Methods

- **IntFeature/FloatFeature**
  - `get_range()`: Get min/max range
  - `get_increment()`: Get increment

- **StringFeature**
  - `get_max_length()`: Get maximum string length

- **EnumFeature**
  - `get_all_entries()`: Get all possible entries
  - `get_available_entries()`: Get currently available entries
  - `get_entry(val_or_name)`: Get specific entry

- **CommandFeature**
  - `run()`: Execute command
  - `is_done()`: Check if execution is complete

- **RawFeature**
  - `length()`: Get length of byte sequence

## 5. Stream

The `Stream` class provides access to a data stream from a camera.

### Key Methods

- `get_frame()`: Get a single frame
- `get_frame_generator()`: Generate frames one by one
- `start_streaming(handler)`: Start streaming
- `stop_streaming()`: Stop streaming
- `queue_frame(frame)`: Return a frame to the queue
- `is_streaming()`: Check if streaming

## 6. Interface

The `Interface` class represents a physical interface like USB or GigE.

### Key Methods

- `get_id()`: Get interface ID
- `get_name()`: Get interface name
- `get_type()`: Get interface type
- `get_transport_layer()`: Get transport layer
- `get_cameras()`: Get associated cameras
- `get_all_features()`: Get all features

## 7. TransportLayer

The `TransportLayer` class represents different transport layer technologies.

### Key Methods

- `get_id()`: Get transport layer ID
- `get_name()`: Get display name
- `get_model_name()`: Get model name
- `get_vendor()`: Get vendor
- `get_version()`: Get version
- `get_path()`: Get file path
- `get_type()`: Get transport layer type
- `get_interfaces()`: Get associated interfaces
- `get_cameras()`: Get associated cameras

## 8. Enumerations

### AccessMode

- `None_`: No access
- `Full`: Read and write access
- `Read`: Read-only access
- `Exclusive`: Exclusive read/write access
- `Unknown`: Unknown access mode

### PixelFormat

Numerous pixel formats are supported:

- Mono formats: `Mono8`, `Mono10`, `Mono12`, etc.
- Bayer formats: `BayerGR8`, `BayerRG8`, etc.
- RGB/BGR formats: `Rgb8`, `Bgr8`, etc.
- RGBA/BGRA formats: `Rgba8`, `Bgra8`, etc.
- YUV formats: `Yuv411`, `Yuv422`, etc.

### FrameStatus

- `Complete`: Frame is complete
- `Incomplete`: Frame could not be filled
- `TooSmall`: Frame buffer was too small
- `Invalid`: Frame buffer was invalid

### AllocationMode

- `AnnounceFrame`: Buffer allocated by VmbPy
- `AllocAndAnnounceFrame`: Buffer allocated by Transport Layer

### TransportLayerType

- `GEV`: GigE Vision
- `U3V`: USB3 Vision
- `CL`: Camera Link
- `IIDC`: IIDC 1394
- And many others

## 9. Error Handling

VmbPy provides several error types:

- `VmbCameraError`: Camera-related errors
- `VmbFeatureError`: Feature access errors
- `VmbFrameError`: Frame data errors
- `VmbInterfaceError`: Interface-related errors
- `VmbTransportLayerError`: Transport layer errors
- `VmbSystemError`: System-wide errors
- `VmbTimeout`: Operation timeouts
- `VmbChunkError`: Chunk data errors

## 10. Complete Example: Capturing and Processing Images

```python
import vmbpy
import numpy as np
import cv2
import time

def frame_handler(cam, stream, frame):
    """
    Handler called for each frame during streaming
    """
    print(f"Frame ID: {frame.get_id()}")
    
    # Process the frame
    image = frame.as_opencv_image()
    
    # Apply some processing (e.g., edge detection)
    edges = cv2.Canny(image, 100, 200)
    
    # Display the result
    cv2.imshow("Processed Frame", edges)
    cv2.waitKey(1)
    
    # Important: Queue the frame back to continue streaming
    cam.queue_frame(frame)

def main():
    # Get VmbSystem instance
    with vmbpy.VmbSystem.get_instance() as vmb:
        # Print API version
        print(f"VmbPy version: {vmb.get_version()}")
        
        # Get all available cameras
        cameras = vmb.get_all_cameras()
        
        if not cameras:
            print("No cameras found!")
            return
        
        # Select the first camera
        with cameras[0] as cam:
            # Print camera info
            print(f"Camera ID: {cam.get_id()}")
            print(f"Camera model: {cam.get_model()}")
            print(f"Camera name: {cam.get_name()}")
            
            # Configure some features
            try:
                # Set pixel format to BGR8 for easy OpenCV processing
                cam.set_pixel_format(vmbpy.PixelFormat.Bgr8)
                
                # Configure exposure if available
                try:
                    exposure_feature = cam.get_feature_by_name("ExposureTime")
                    exposure_range = exposure_feature.get_range()
                    print(f"Exposure range: {exposure_range}")
                    
                    # Set exposure to middle of range
                    exposure_value = (exposure_range[0] + exposure_range[1]) / 2
                    exposure_feature.set(exposure_value)
                    print(f"Exposure set to: {exposure_value}")
                except vmbpy.VmbFeatureError:
                    print("Exposure feature not available")
                
                # Example 1: Get a single frame
                print("Acquiring single frame...")
                frame = cam.get_frame()
                cv2.imshow("Single Frame", frame.as_opencv_image())
                cv2.waitKey(1000)
                
                # Example 2: Use frame generator for multiple frames
                print("Using frame generator...")
                for frame in cam.get_frame_generator(limit=10):
                    cv2.imshow("Frame Generator", frame.as_opencv_image())
                    if cv2.waitKey(100) == 27:  # ESC key
                        break
                
                # Example 3: Start streaming with callback
                print("Starting streaming mode...")
                cam.start_streaming(frame_handler)
                
                # Run for 10 seconds
                time.sleep(10)
                
                # Stop streaming
                cam.stop_streaming()
                
            except vmbpy.VmbFeatureError as e:
                print(f"Feature error: {e}")
            except vmbpy.VmbFrameError as e:
                print(f"Frame error: {e}")
            except vmbpy.VmbTimeout as e:
                print(f"Timeout error: {e}")
            
            cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
```

## 11. Advanced Topics

### 11.1 Chunk Data

Chunk data allows accessing additional metadata alongside the image:

```python
def chunk_callback(feature_container):
    # Access chunk features
    for feature in feature_container.get_all_features():
        print(f"{feature.get_name()}: {feature.get()}")

# In your frame handling code:
if frame.contains_chunk_data():
    frame.access_chunk_data(chunk_callback)
```

### 11.2 Event Handling

Register for camera and interface events:

```python
def camera_change_handler(camera, event):
    if event == vmbpy.CameraEvent.Detected:
        print(f"Camera detected: {camera.get_id()}")
    elif event == vmbpy.CameraEvent.Missing:
        print(f"Camera disconnected: {camera.get_id()}")

with vmbpy.VmbSystem.get_instance() as vmb:
    vmb.register_camera_change_handler(camera_change_handler)
    # Keep running to receive events
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        pass
```

### 11.3 Loading and Saving Settings

Save camera configuration to XML:

```python
with cam as camera:
    # Configure camera features
    camera.get_feature_by_name("ExposureTime").set(10000)
    camera.get_feature_by_name("Gain").set(5.0)
    
    # Save settings
    camera.save_settings("camera_config.xml")
    
# Later, load settings
with cam as camera:
    camera.load_settings("camera_config.xml")
```

### 11.4 Multiple Cameras

Working with multiple cameras simultaneously:

```python
with vmbpy.VmbSystem.get_instance() as vmb:
    cameras = vmb.get_all_cameras()
    
    # Open all cameras
    with contextlib.ExitStack() as stack:
        opened_cameras = [stack.enter_context(cam) for cam in cameras]
        
        # Configure all cameras similarly
        for cam in opened_cameras:
            cam.set_pixel_format(vmbpy.PixelFormat.Mono8)
            
        # Get a frame from each camera
        frames = [cam.get_frame() for cam in opened_cameras]
        
        # Process frames
        for i, frame in enumerate(frames):
            image = frame.as_numpy_ndarray()
            cv2.imwrite(f"camera_{i}.png", image)
```

## 12. Best Practices

1. **Always use context managers** (`with` statements) when working with VmbSystem, Camera, and other objects to ensure proper resource cleanup.

2. **Handle errors appropriately** using try-except blocks to catch VmbPy-specific exceptions.

3. **Return frames to the queue** when using streaming mode to avoid buffer exhaustion.

4. **Check feature availability** before trying to access or modify features, as not all cameras support all features.

5. **Use appropriate pixel formats** based on your application needs:
   - Mono8 for grayscale processing
   - BGR8 for color processing with OpenCV
   - Mono16/RGB16 for high bit-depth applications

6. **Set appropriate timeouts** for frame acquisition based on your application requirements.

7. **Consider memory management** when processing large frame sequences.

## 13. Performance Optimization

### 13.1 Buffer Management

Optimal buffer management is crucial for high-performance imaging:

```python
# Increase buffer count for smoother streaming
cam.start_streaming(frame_handler, buffer_count=10)

# Use a fixed set of frames to avoid memory allocation overhead
frames = []
for _ in range(10):
    frames.append(cam.get_frame())
    cam.queue_frame(frames[-1])  # Queue it back immediately

# Use the frames for processing later
for frame in frames:
    # Process frame
    pass
```

### 13.2 Pixel Format Selection

Choosing the right pixel format can significantly impact performance:

- Use `Mono8` for fastest processing when color isn't needed
- Use packed formats (`Mono12p` instead of `Mono12`) for bandwidth efficiency
- Consider hardware acceleration for format conversion

```python
# Find intersection of formats supported by camera and your processing pipeline
camera_formats = cam.get_pixel_formats()
processing_formats = [vmbpy.PixelFormat.Mono8, vmbpy.PixelFormat.Bgr8]
usable_formats = vmbpy.intersect_pixel_formats(camera_formats, processing_formats)

if usable_formats:
    cam.set_pixel_format(usable_formats[0])
else:
    # Need to use format conversion
    cam.set_pixel_format(camera_formats[0])
    # Will need to convert frames later
```

### 13.3 Memory Pre-allocation for Conversion

```python
# Pre-allocate conversion buffer
original_frame = cam.get_frame()
converted_frame = original_frame.convert_pixel_format(vmbpy.PixelFormat.Bgr8)
conversion_buffer = converted_frame.get_buffer()

# For subsequent frames, reuse the buffer
for frame in cam.get_frame_generator(limit=100):
    converted = frame.convert_pixel_format(
        vmbpy.PixelFormat.Bgr8, 
        destination_buffer=conversion_buffer
    )
    # Process the converted frame
```

## 14. Industrial Imaging Applications

### 14.1 Triggering

Many industrial applications require external triggering for synchronized image acquisition:

```python
with cam as camera:
    # Configure triggering
    try:
        # Set trigger mode on
        trigger_mode = camera.get_feature_by_name("TriggerMode")
        trigger_mode.set("On")
        
        # Set trigger source to Line1 (external trigger)
        trigger_source = camera.get_feature_by_name("TriggerSource")
        trigger_source.set("Line1")
        
        # Set trigger activation to rising edge
        trigger_activation = camera.get_feature_by_name("TriggerActivation")
        trigger_activation.set("RisingEdge")
        
        print("Camera configured for external triggering")
        
        # Capture a sequence of triggered frames
        for i in range(10):
            # Wait for external trigger to happen
            frame = camera.get_frame(timeout_ms=5000)  # Longer timeout for trigger
            
            # Process triggered frame
            cv2.imwrite(f"triggered_frame_{i}.png", frame.as_opencv_image())
            
    except vmbpy.VmbFeatureError as e:
        print(f"Trigger configuration error: {e}")
```

### 14.2 Multi-Camera Synchronization

For applications requiring multiple synchronized cameras:

```python
def configure_for_sync(camera):
    """Configure a camera for synchronized acquisition"""
    # Set to same trigger source
    camera.get_feature_by_name("TriggerMode").set("On")
    camera.get_feature_by_name("TriggerSource").set("Line1")  # Shared trigger line
    
    # Set same exposure
    camera.get_feature_by_name("ExposureTime").set(10000)
    
    return camera

with vmbpy.VmbSystem.get_instance() as vmb:
    cameras = vmb.get_all_cameras()
    
    # Open and configure all cameras
    with contextlib.ExitStack() as stack:
        opened_cameras = [stack.enter_context(configure_for_sync(cam)) for cam in cameras]
        
        # Start streaming on all cameras
        for cam in opened_cameras:
            cam.start_streaming(lambda c, s, f: cam.queue_frame(f))
        
        # Trigger acquisition (example: software trigger)
        for cam in opened_cameras:
            if "TriggerSoftware" in [f.get_name() for f in cam.get_all_features()]:
                cam.get_feature_by_name("TriggerSoftware").run()
                break  # Only trigger one camera if they share the trigger line
        
        # Get frames from all cameras
        frames = []
        for cam in opened_cameras:
            frames.append(cam.get_frame(timeout_ms=5000))
        
        # Process synchronized frames
        for i, frame in enumerate(frames):
            cv2.imwrite(f"sync_camera_{i}.png", frame.as_opencv_image())
        
        # Stop streaming on all cameras
        for cam in opened_cameras:
            cam.stop_streaming()
```

### 14.3 Region of Interest (ROI)

Setting a region of interest to increase frame rates or focus on specific areas:

```python
with cam as camera:
    # Get original dimensions
    width_feature = camera.get_feature_by_name("Width")
    height_feature = camera.get_feature_by_name("Height")
    original_width = width_feature.get()
    original_height = height_feature.get()
    
    # Get dimension limits
    width_range = width_feature.get_range()
    height_range = height_feature.get_range()
    
    # Get offset features
    offset_x = camera.get_feature_by_name("OffsetX")
    offset_y = camera.get_feature_by_name("OffsetY")
    
    # Set Region of Interest (centered)
    roi_width = original_width // 2
    roi_height = original_height // 2
    
    # Calculate offsets to center the ROI
    x_offset = (original_width - roi_width) // 2
    y_offset = (original_height - roi_height) // 2
    
    # Important: Set offset first, then size
    offset_x.set(x_offset)
    offset_y.set(y_offset)
    width_feature.set(roi_width)
    height_feature.set(roi_height)
    
    print(f"ROI set to {roi_width}x{roi_height} at ({x_offset},{y_offset})")
    
    # Capture with ROI
    frame = camera.get_frame()
    cv2.imwrite("roi_frame.png", frame.as_opencv_image())
    
    # Restore original dimensions
    # Important: Set size first, then offset
    width_feature.set(original_width)
    height_feature.set(original_height)
    offset_x.set(0)
    offset_y.set(0)
```

## 15. Integration with Other Libraries

### 15.1 Integration with NumPy and SciPy

```python
import numpy as np
from scipy import ndimage

with cam as camera:
    frame = camera.get_frame()
    
    # Convert to NumPy array
    img_array = frame.as_numpy_ndarray()
    
    # Apply SciPy filters
    filtered = ndimage.gaussian_filter(img_array, sigma=2)
    edges = ndimage.sobel(img_array)
    
    # Calculate statistics
    mean_value = np.mean(img_array)
    std_dev = np.std(img_array)
    min_val = np.min(img_array)
    max_val = np.max(img_array)
    
    print(f"Image statistics: Mean={mean_value:.2f}, StdDev={std_dev:.2f}, Min={min_val}, Max={max_val}")
```

### 15.2 Integration with OpenCV

```python
import cv2
import numpy as np

def process_frame(frame):
    # Convert to OpenCV format
    img = frame.as_opencv_image()
    
    # Basic OpenCV operations
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)
    
    # Find contours
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Draw contours on original image
    result = img.copy()
    cv2.drawContours(result, contours, -1, (0, 255, 0), 2)
    
    # Calculate and print some metrics
    num_objects = len(contours)
    total_area = sum(cv2.contourArea(c) for c in contours)
    
    print(f"Found {num_objects} objects with total area {total_area:.2f} pixels")
    
    return result

with vmbpy.VmbSystem.get_instance() as vmb:
    with vmb.get_all_cameras()[0] as cam:
        # Configure camera for optimal OpenCV processing
        cam.set_pixel_format(vmbpy.PixelFormat.Bgr8)
        
        # Process a sequence of frames
        for frame in cam.get_frame_generator(limit=10):
            result = process_frame(frame)
            
            # Display result
            cv2.imshow("Processed Frame", result)
            if cv2.waitKey(100) == 27:  # ESC to exit
                break
        
        cv2.destroyAllWindows()
```

### 15.3 Integration with Machine Learning Frameworks

```python
import cv2
import numpy as np
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions

# Load pre-trained model
model = MobileNetV2(weights='imagenet')

def classify_frame(frame):
    # Convert to OpenCV format
    img = frame.as_opencv_image()
    
    # Resize to model input size
    img_resized = cv2.resize(img, (224, 224))
    
    # Preprocess for model
    img_array = np.expand_dims(img_resized, axis=0)
    img_preprocessed = preprocess_input(img_array)
    
    # Predict
    predictions = model.predict(img_preprocessed)
    decoded = decode_predictions(predictions, top=3)[0]
    
    # Print results
    for i, (imagenet_id, label, score) in enumerate(decoded):
        print(f"Top {i+1}: {label} ({score:.2f})")
    
    return img, decoded

with vmbpy.VmbSystem.get_instance() as vmb:
    with vmb.get_all_cameras()[0] as cam:
        cam.set_pixel_format(vmbpy.PixelFormat.Bgr8)
        
        # Classify a single frame
        frame = cam.get_frame()
        img, predictions = classify_frame(frame)
        
        # Display result
        for i, (_, label, score) in enumerate(predictions):
            text = f"{label}: {score:.2f}"
            cv2.putText(img, text, (10, 30 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        cv2.imshow("Classification Result", img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
```

## 16. Troubleshooting

### 16.1 Common Error Handling Patterns

```python
try:
    # Attempt to connect to camera
    with cam as camera:
        try:
            # Attempt to configure camera
            camera.set_pixel_format(vmbpy.PixelFormat.Bgr8)
            
            try:
                # Attempt to acquire frame
                frame = camera.get_frame(timeout_ms=1000)
                
                # Process frame
                cv2.imwrite("captured_frame.png", frame.as_opencv_image())
                
            except vmbpy.VmbTimeout:
                print("Frame acquisition timed out. Check if camera is receiving trigger signals.")
            except vmbpy.VmbFrameError as e:
                print(f"Frame error: {e}. Check pixel format and buffer size settings.")
                
        except vmbpy.VmbFeatureError as e:
            print(f"Feature error: {e}. Feature may not be available or value out of range.")
            
except vmbpy.VmbCameraError as e:
    print(f"Camera error: {e}. Camera may be disconnected or in use by another application.")
```

### 16.2 Diagnostic Information

```python
def print_camera_diagnostics(camera):
    """Print diagnostic information for a camera"""
    print("=== Camera Diagnostics ===")
    print(f"ID: {camera.get_id()}")
    print(f"Name: {camera.get_name()}")
    print(f"Model: {camera.get_model()}")
    print(f"Serial: {camera.get_serial()}")
    print(f"Interface ID: {camera.get_interface_id()}")
    print(f"Access Mode: {camera.get_access_mode()}")
    print(f"Permitted Access Modes: {camera.get_permitted_access_modes()}")
    print(f"Is Streaming: {camera.is_streaming()}")
    
    print("\n=== Key Features ===")
    try:
        features_to_check = [
            "Width", "Height", "PixelFormat", 
            "ExposureTime", "ExposureAuto", 
            "Gain", "GainAuto",
            "TriggerMode", "TriggerSource", 
            "AcquisitionMode", "AcquisitionFrameRate"
        ]
        
        for feat_name in features_to_check:
            try:
                feature = camera.get_feature_by_name(feat_name)
                if isinstance(feature, vmbpy.IntFeature) or isinstance(feature, vmbpy.FloatFeature):
                    value = feature.get()
                    range_vals = feature.get_range()
                    print(f"{feat_name}: {value} (Range: {range_vals[0]} to {range_vals[1]})")
                elif isinstance(feature, vmbpy.EnumFeature):
                    value = feature.get()
                    options = [entry.as_tuple()[0] for entry in feature.get_available_entries()]
                    print(f"{feat_name}: {value.as_tuple()[0]} (Options: {options})")
                else:
                    print(f"{feat_name}: {feature.get()}")
            except vmbpy.VmbFeatureError:
                print(f"{feat_name}: Not available")
    except Exception as e:
        print(f"Error retrieving features: {e}")
    
    print("\n=== Supported Pixel Formats ===")
    try:
        formats = camera.get_pixel_formats()
        for fmt in formats:
            print(f"- {fmt.name}")
    except Exception as e:
        print(f"Error retrieving pixel formats: {e}")

# Usage
with vmbpy.VmbSystem.get_instance() as vmb:
    cameras = vmb.get_all_cameras()
    if cameras:
        with cameras[0] as cam:
            print_camera_diagnostics(cam)
```

### 16.3 Connection Issues

Common connection problems and their resolutions:

1. **Camera not found**:
   - Check physical connections
   - Verify that camera is powered on
   - Check if another application is using the camera
   - For GigE cameras, check network configuration

2. **Access denied errors**:
   - Check if camera is in use by another application
   - Try different access modes
   - For USB cameras, check user permissions
   - For GigE cameras, check firewall settings

3. **Feature access errors**:
   - Check if feature is supported by the camera model
   - Verify feature visibility level and access rights
   - For interdependent features, check if prerequisite features are configured

4. **Streaming issues**:
   - Check bandwidth settings for GigE cameras
   - Reduce resolution or frame rate if bandwidth is limited
   - Increase packet size for GigE cameras if network supports jumbo frames
   - Verify that enough buffers are allocated

## 17. Advanced Feature Manipulation

### 17.1 Feature Dependency Management

Many camera features have dependencies that must be handled properly:

```python
def configure_feature_with_dependencies(camera, feature_name, desired_value):
    """Configure a feature while managing its dependencies"""
    try:
        feature = camera.get_feature_by_name(feature_name)
        
        # Get features selected by this feature
        dependencies = camera.get_features_selected_by(feature)
        if dependencies:
            print(f"Feature {feature_name} selects these dependencies:")
            for dep in dependencies:
                print(f"- {dep.get_name()}")
        
        # Check if feature is writeable
        if not feature.is_writeable():
            print(f"Feature {feature_name} is not currently writeable")
            
            # Find dependencies that might be affecting writeability
            for dep in camera.get_all_features():
                selected = camera.get_features_selected_by(dep)
                if any(feat.get_name() == feature_name for feat in selected):
                    print(f"Feature {feature_name} is affected by {dep.get_name()}")
                    print(f"Current value: {dep.get()}")
                    
                    # Example: If we're trying to set ExposureTime but ExposureAuto is on
                    if dep.get_name() == "ExposureAuto" and dep.get() != "Off":
                        print("Setting ExposureAuto to Off")
                        dep.set("Off")
        
        # Now try to set the value
        feature.set(desired_value)
        print(f"Successfully set {feature_name} to {desired_value}")
        
    except vmbpy.VmbFeatureError as e:
        print(f"Error configuring feature {feature_name}: {e}")

# Example usage
with cam as camera:
    # Configure ExposureTime while handling ExposureAuto dependency
    configure_feature_with_dependencies(camera, "ExposureTime", 10000)
```

### 17.2 Feature Change Handlers

Monitor feature changes in real-time:

```python
def feature_change_callback(feature):
    """Callback executed when a feature value changes"""
    try:
        print(f"Feature {feature.get_name()} changed to {feature.get()}")
    except vmbpy.VmbFeatureError:
        print(f"Feature {feature.get_name()} changed but couldn't read value")

# Monitor temperature changes on camera
with cam as camera:
    try:
        temp_feature = camera.get_feature_by_name("DeviceTemperature")
        
        # Register change handler
        temp_feature.register_change_handler(feature_change_callback)
        
        print("Monitoring temperature for 30 seconds...")
        
        # Start streaming to make sure temperature updates
        camera.start_streaming(lambda c, s, f: c.queue_frame(f))
        
        # Wait for some time
        time.sleep(30)
        
        # Unregister handler
        temp_feature.unregister_change_handler(feature_change_callback)
        
        # Stop streaming
        camera.stop_streaming()
        
    except vmbpy.VmbFeatureError as e:
        print(f"Temperature monitoring error: {e}")
```

### 17.3 Creating Feature Maps

Generate a complete map of feature dependencies:

```python
def build_feature_dependency_map(camera):
    """Build a dependency map of all features"""
    dependency_map = {}
    
    for feature in camera.get_all_features():
        try:
            name = feature.get_name()
            selected_features = camera.get_features_selected_by(feature)
            
            if selected_features:
                dependency_map[name] = [f.get_name() for f in selected_features]
            
        except vmbpy.VmbFeatureError:
            pass  # Skip if can't access
    
    return dependency_map

# Usage
with cam as camera:
    dependency_map = build_feature_dependency_map(camera)
    
    # Print dependencies of common features
    for feature_name, dependencies in dependency_map.items():
        if dependencies:
            print(f"{feature_name} affects: {', '.join(dependencies)}")
    
    # Find which features affect exposure
    for feature_name, dependencies in dependency_map.items():
        if "ExposureTime" in dependencies:
            print(f"ExposureTime is affected by: {feature_name}")
```

## 18. Working with Camera Events

### 18.1 Camera Discovery Events

Setup a monitoring system for camera connect/disconnect events:

```python
import threading
import time
import vmbpy

def camera_event_handler(camera, event):
    """Handle camera connect/disconnect events"""
    if event == vmbpy.CameraEvent.Detected:
        print(f"Camera detected: {camera.get_id()}")
        # Try to get more info about the camera
        try:
            with camera:
                print(f"  Model: {camera.get_model()}")
                print(f"  Serial: {camera.get_serial()}")
        except vmbpy.VmbCameraError:
            print("  Unable to open camera for more details")
    
    elif event == vmbpy.CameraEvent.Missing:
        print(f"Camera disconnected: {camera.get_id()}")
    
    elif event == vmbpy.CameraEvent.Reachable:
        print(f"Camera became reachable: {camera.get_id()}")
    
    elif event == vmbpy.CameraEvent.Unreachable:
        print(f"Camera became unreachable: {camera.get_id()}")

def interface_event_handler(interface, event):
    """Handle interface connect/disconnect events"""
    if event == vmbpy.InterfaceEvent.Detected:
        print(f"Interface detected: {interface.get_id()}")
    
    elif event == vmbpy.InterfaceEvent.Missing:
        print(f"Interface disconnected: {interface.get_id()}")
    
    elif event == vmbpy.InterfaceEvent.Reachable:
        print(f"Interface became reachable: {interface.get_id()}")
    
    elif event == vmbpy.InterfaceEvent.Unreachable:
        print(f"Interface became unreachable: {interface.get_id()}")

def monitor_system_events():
    """Monitor camera system events in background thread"""
    with vmbpy.VmbSystem.get_instance() as vmb:
        # Register event handlers
        vmb.register_camera_change_handler(camera_event_handler)
        vmb.register_interface_change_handler(interface_event_handler)
        
        # Print existing devices
        print("Currently available cameras:")
        for camera in vmb.get_all_cameras():
            print(f"- {camera.get_id()} ({camera.get_model() if hasattr(camera, 'get_model') else 'Unknown'})")
        
        print("Currently available interfaces:")
        for interface in vmb.get_all_interfaces():
            print(f"- {interface.get_id()} ({interface.get_type().name})")
        
        print("\nMonitoring for device changes. Connect or disconnect cameras to see events.")
        
        try:
            # Keep thread running to receive events
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            pass
        finally:
            # Clean up event handlers
            vmb.unregister_all_camera_change_handlers()
            vmb.unregister_all_interface_change_handlers()

# Run monitor in background thread
monitor_thread = threading.Thread(target=monitor_system_events)
monitor_thread.daemon = True  # Allow program to exit even if thread is running
monitor_thread.start()

# Main program can continue doing other things
try:
    while True:
        # Do other work in main thread
        time.sleep(1)
except KeyboardInterrupt:
    print("Exiting program")
```

### 18.2 Custom Feature-Based Events

Create custom events based on feature changes:

```python
import threading
import time
import vmbpy

class TemperatureMonitor:
    def __init__(self, camera, threshold=50.0, check_interval=1.0):
        self.camera = camera
        self.threshold = threshold
        self.check_interval = check_interval
        self.running = False
        self.monitor_thread = None
        self.callbacks = []
    
    def add_callback(self, callback):
        """Add callback to be executed when temperature exceeds threshold"""
        self.callbacks.append(callback)
    
    def temperature_changed(self, feature):
        """Callback for feature change"""
        try:
            current_temp = feature.get()
            if current_temp > self.threshold:
                # Execute all registered callbacks
                for callback in self.callbacks:
                    callback(self.camera, current_temp)
        except vmbpy.VmbFeatureError:
            pass
    
    def start(self):
        """Start temperature monitoring"""
        if self.running:
            return
        
        try:
            # Get temperature feature
            temp_feature = self.camera.get_feature_by_name("DeviceTemperature")
            
            # Register change handler
            temp_feature.register_change_handler(self.temperature_changed)
            
            self.running = True
            print(f"Temperature monitoring started (threshold: {self.threshold}°C)")
            
        except vmbpy.VmbFeatureError as e:
            print(f"Failed to start temperature monitoring: {e}")
    
    def stop(self):
        """Stop temperature monitoring"""
        if not self.running:
            return
        
        try:
            # Get temperature feature
            temp_feature = self.camera.get_feature_by_name("DeviceTemperature")
            
            # Unregister change handler
            temp_feature.unregister_change_handler(self.temperature_changed)
            
            self.running = False
            print("Temperature monitoring stopped")
            
        except vmbpy.VmbFeatureError as e:
            print(f"Error stopping temperature monitoring: {e}")

# Example usage
def high_temperature_alert(camera, temperature):
    print(f"WARNING: Camera {camera.get_id()} temperature high: {temperature}°C")
    # Could send email, SMS, or perform other actions here

with vmbpy.VmbSystem.get_instance() as vmb:
    cameras = vmb.get_all_cameras()
    
    if cameras:
        with cameras[0] as cam:
            # Create temperature monitor
            temp_monitor = TemperatureMonitor(cam, threshold=45.0)
            
            # Add callback
            temp_monitor.add_callback(high_temperature_alert)
            
            # Start monitoring
            temp_monitor.start()
            
            # Start streaming to ensure temperature updates
            cam.start_streaming(lambda c, s, f: c.queue_frame(f))
            
            try:
                print("Monitoring temperature for 60 seconds...")
                time.sleep(60)
            finally:
                # Stop monitoring
                temp_monitor.stop()
                cam.stop_streaming()
```

## 19. Advanced Image Analysis

### 19.1 Real-time Histogram Analysis

```python
import vmbpy
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

class HistogramAnalyzer:
    def __init__(self, camera):
        self.camera = camera
        self.fig, self.axes = plt.subplots(2, 2, figsize=(12, 8))
        self.bins = np.arange(256)
        
        # Flatten axes for easier indexing
        self.axes = self.axes.flatten()
        
        # Initialize histograms
        self.hist_lines = []
        colors = ['gray', 'blue', 'green', 'red']
        titles = ['Grayscale', 'Blue Channel', 'Green Channel', 'Red Channel']
        
        for i, (ax, color, title) in enumerate(zip(self.axes, colors, titles)):
            line, = ax.plot(self.bins, np.zeros(256), color=color, lw=2)
            self.hist_lines.append(line)
            ax.set_xlim(0, 255)
            ax.set_title(title)
            if i == 0:
                ax.set_ylabel('Frequency')
            if i >= 2:
                ax.set_xlabel('Pixel Value')
    
    def update_histogram(self, frame):
        """Update histograms with current frame"""
        try:
            # Convert to numpy array
            img = frame.as_opencv_image()
            
            # Update grayscale histogram
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            gray_hist = cv2.calcHist([gray], [0], None, [256], [0, 256]).flatten()
            self.hist_lines[0].set_ydata(gray_hist)
            self.axes[0].set_ylim(0, gray_hist.max() * 1.1)
            
            # Update color channel histograms
            for i, color in enumerate(['blue', 'green', 'red']):
                hist = cv2.calcHist([img], [i], None, [256], [0, 256]).flatten()
                self.hist_lines[i+1].set_ydata(hist)
                self.axes[i+1].set_ylim(0, hist.max() * 1.1)
            
            # Calculate statistics
            mean_value = np.mean(gray)
            std_dev = np.std(gray)
            
            # Update the title with statistics
            self.fig.suptitle(f"Image Histogram - Mean: {mean_value:.1f}, StdDev: {std_dev:.1f}", fontsize=14)
            
            return self.hist_lines
        except Exception as e:
            print(f"Error updating histogram: {e}")
            return self.hist_lines
    
    def start_analysis(self):
        """Start real-time histogram analysis"""
        # Configure camera for analysis
        self.camera.set_pixel_format(vmbpy.PixelFormat.Bgr8)
        
        # Start streaming with histogram updates
        def frame_handler(cam, stream, frame):
            # Update histogram
            self.update_histogram(frame)
            
            # Redraw the figure
            self.fig.canvas.draw()
            self.fig.canvas.flush_events()
            
            # Queue frame back
            cam.queue_frame(frame)
        
        # Start streaming
        self.camera.start_streaming(frame_handler)
        
        # Show the plot (will block until closed)
        plt.tight_layout()
        plt.show()
        
        # Once plot is closed, stop streaming
        self.camera.stop_streaming()

# Usage
with vmbpy.VmbSystem.get_instance() as vmb:
    cameras = vmb.get_all_cameras()
    
    if cameras:
        with cameras[0] as cam:
            analyzer = HistogramAnalyzer(cam)
            analyzer.start_analysis()
```

### 19.2 Frame Averaging for Noise Reduction

```python
import vmbpy
import numpy as np
import cv2

def average_frames(camera, num_frames=10):
    """Capture multiple frames and average them to reduce noise"""
    # Configure camera
    camera.set_pixel_format(vmbpy.PixelFormat.Mono8)  # Use Mono8 for simplicity
    
    # Get a single frame to determine dimensions
    frame = camera.get_frame()
    height = frame.get_height()
    width = frame.get_width()
    
    # Create accumulator
    accumulator = np.zeros((height, width), dtype=np.float32)
    
    print(f"Capturing {num_frames} frames for averaging...")
    
    # Capture frames and accumulate
    for i in range(num_frames):
        frame = camera.get_frame()
        img = frame.as_numpy_ndarray()
        
        # Add to accumulator
        accumulator += img.astype(np.float32)
        
        print(f"Captured frame {i+1}/{num_frames}")
    
    # Calculate average
    avg_img = (accumulator / num_frames).astype(np.uint8)
    
    # For comparison, also get a single frame
    single_frame = camera.get_frame()
    single_img = single_frame.as_numpy_ndarray()
    
    # Calculate noise metrics
    single_std = np.std(single_img)
    avg_std = np.std(avg_img)
    
    print(f"Standard deviation (noise metric):")
    print(f"  Single frame: {single_std:.2f}")
    print(f"  Averaged frame: {avg_std:.2f}")
    print(f"  Noise reduction: {(1 - avg_std/single_std)*100:.1f}%")
    
    # Display results
    cv2.imshow("Single Frame", single_img)
    cv2.imshow("Averaged Frame", avg_img)
    
    # Create a difference image to highlight noise
    diff = cv2.absdiff(single_img, avg_img)
    # Amplify difference for visibility
    diff = cv2.multiply(diff, 5)
    cv2.imshow("Difference (Noise)", diff)
    
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    return avg_img

# Usage
with vmbpy.VmbSystem.get_instance() as vmb:
    cameras = vmb.get_all_cameras()
    
    if cameras:
        with cameras[0] as cam:
            # Try different numbers of frames to average
            averaged_image = average_frames(cam, num_frames=32)
```

### 19.3 High Dynamic Range (HDR) Imaging

```python
import vmbpy
import numpy as np
import cv2

def capture_hdr(camera, exposure_times):
    """Capture multiple images at different exposures for HDR"""
    # Get exposure feature
    try:
        exposure_feature = camera.get_feature_by_name("ExposureTime")
        
        # Make sure auto exposure is off
        auto_exposure = camera.get_feature_by_name("ExposureAuto")
        original_auto = auto_exposure.get()
        if original_auto != "Off":
            print(f"Turning off ExposureAuto (was {original_auto})")
            auto_exposure.set("Off")
        
        # Set pixel format for HDR processing
        camera.set_pixel_format(vmbpy.PixelFormat.Mono16)
        
        # Capture images at different exposures
        images = []
        times = []  # Actual exposure times (may differ from requested)
        
        for exp_time in exposure_times:
            # Set exposure time
            print(f"Setting exposure to {exp_time} μs")
            exposure_feature.set(exp_time)
            
            # Wait for exposure to take effect
            time.sleep(0.2)
            
            # Capture frame
            frame = camera.get_frame()
            img = frame.as_numpy_ndarray()
            
            # Read back actual exposure time
            actual_exp = exposure_feature.get()
            times.append(actual_exp)
            
            # Add to images list
            images.append(img)
            
            print(f"Captured image at {actual_exp} μs")
        
        # Restore original auto exposure setting
        if original_auto != "Off":
            auto_exposure.set(original_auto)
        
        # Create HDR image using OpenCV's merge method
        print("Creating HDR image...")
        
        # Create array of exposure times (convert to seconds)
        times_array = np.array(times, dtype=np.float32) / 1_000_000.0
        
        # Create HDR merge object
        merge_debevec = cv2.createMergeDebevec()
        hdr = merge_debevec.process(images, times=times_array)
        
        # Tone map to display result
        tonemap = cv2.createTonemap(gamma=2.2)
        tone_mapped = tonemap.process(hdr)
        
        # Convert to 8-bit for display
        tone_mapped_8bit = np.clip(tone_mapped * 255, 0, 255).astype(np.uint8)
        
        # Display results
        for i, img in enumerate(images):
            # Normalize for display (12/14/16-bit to 8-bit)
            normalized = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)
            normalized = normalized.astype(np.uint8)
            cv2.imshow(f"Exposure {times[i]/1000:.1f} ms", normalized)
        
        cv2.imshow("HDR Result", tone_mapped_8bit)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        
        return hdr, tone_mapped_8bit
        
    except vmbpy.VmbFeatureError as e:
        print(f"HDR capture error: {e}")
        return None, None

# Usage
with vmbpy.VmbSystem.get_instance() as vmb:
    cameras = vmb.get_all_cameras()
    
    if cameras:
        with cameras[0] as cam:
            # Define exposure times (in μs) from short to long
            exposures = [1000, 4000, 16000, 64000]
            
            # Capture HDR images
            hdr, tone_mapped = capture_hdr(cam, exposures)
            
            if hdr is not None:
                # Save results
                cv2.imwrite("hdr_tone_mapped.jpg", tone_mapped)
                # Save HDR in OpenEXR format if OpenCV was built with OpenEXR support
                try:
                    cv2.imwrite("hdr_image.exr", hdr)
                except:
                    print("Could not save EXR file, OpenCV may not have OpenEXR support")
```

## 20. Logging and Diagnostic Tools

### 20.1 Comprehensive Logging System

```python
import vmbpy
import logging
import time
import os
from datetime import datetime

class VmbLogger:
    """Logging system for VmbPy applications"""
    
    def __init__(self, log_dir="logs", level=logging.INFO):
        # Create log directory if it doesn't exist
        os.makedirs(log_dir, exist_ok=True)
        
        # Set up logger
        self.logger = logging.getLogger("vmbpy_logger")
        self.logger.setLevel(level)
        
        # Create handlers for console and file
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Console handler
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        
        # File handler
        file_handler = logging.FileHandler(f"{log_dir}/vmbpy_{timestamp}.log")
        file_handler.setLevel(level)
        
        # Create formatters and add to handlers
        console_format = logging.Formatter("[%(levelname)s] %(message)s")
        file_format = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
        
        console_handler.setFormatter(console_format)
        file_handler.setFormatter(file_format)
        
        # Add handlers to logger
        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)
        
        self.logger.info("VmbLogger initialized")
    
    def log_system_info(self, vmb_system):
        """Log information about the VmbPy system"""
        try:
            self.logger.info(f"VmbPy version: {vmb_system.get_version()}")
            
            # Log transport layers
            transport_layers = vmb_system.get_all_transport_layers()
            self.logger.info(f"Transport layers ({len(transport_layers)}):")
            for tl in transport_layers:
                self.logger.info(f"  - {tl.get_name()} ({tl.get_type().name})")
            
            # Log interfaces
            interfaces = vmb_system.get_all_interfaces()
            self.logger.info(f"Interfaces ({len(interfaces)}):")
            for interface in interfaces:
                self.logger.info(f"  - {interface.get_id()} ({interface.get_type().name})")
            
            # Log cameras
            cameras = vmb_system.get_all_cameras()
            self.logger.info(f"Cameras ({len(cameras)}):")
            for cam in cameras:
                self.logger.info(f"  - {cam.get_id()} ({cam.get_name()})")
                
        except Exception as e:
            self.logger.error(f"Error logging system info: {e}")
    
    def log_camera_info(self, camera):
        """Log detailed information about a camera"""
        try:
            self.logger.info(f"Camera ID: {camera.get_id()}")
            self.logger.info(f"Camera name: {camera.get_name()}")
            self.logger.info(f"Camera model: {camera.get_model()}")
            self.logger.info(f"Camera serial: {camera.get_serial()}")
            self.logger.info(f"Access mode: {camera.get_access_mode()}")
            
            # Log pixel formats
            formats = camera.get_pixel_formats()
            self.logger.info(f"Supported pixel formats ({len(formats)}):")
            for fmt in formats:
                self.logger.info(f"  - {fmt.name}")
                
            # Log key features
            self.logger.info("Key features:")
            features_to_log = [
                "Width", "Height", "PixelFormat", 
                "ExposureTime", "ExposureAuto", 
                "Gain", "GainAuto",
                "TriggerMode", "TriggerSource"
            ]
            
            for feat_name in features_to_log:
                try:
                    feature = camera.get_feature_by_name(feat_name)
                    self.logger.info(f"  - {feat_name}: {feature.get()}")
                except vmbpy.VmbFeatureError:
                    self.logger.info(f"  - {feat_name}: Not available")
                    
        except Exception as e:
            self.logger.error(f"Error logging camera info: {e}")
    
    def log_frame_info(self, frame):
        """Log information about a frame"""
        try:
            self.logger.debug(f"Frame ID: {frame.get_id()}")
            self.logger.debug(f"Frame size: {frame.get_width()}x{frame.get_height()}")
            self.logger.debug(f"Pixel format: {frame.get_pixel_format().name}")
            self.logger.debug(f"Status: {frame.get_status().name}")
            
            # Log timestamp if available
            timestamp = frame.get_timestamp()
            if timestamp is not None:
                self.logger.debug(f"Timestamp: {timestamp}")
                
        except Exception as e:
            self.logger.error(f"Error logging frame info: {e}")
    
    def frame_handler(self, cam, stream, frame):
        """Frame handler with logging"""
        try:
            self.log_frame_info(frame)
            
            # Additional handling logic goes here
            # ...
            
            # Queue frame back
            cam.queue_frame(frame)
            
        except Exception as e:
            self.logger.error(f"Error in frame handler: {e}")
            # Try to queue frame back even if error occurred
            try:
                cam.queue_frame(frame)
            except:
                pass

# Usage
def main():
    # Create logger
    logger = VmbLogger(level=logging.DEBUG)
    
    try:
        with vmbpy.VmbSystem.get_instance() as vmb:
            logger.info("VmbSystem opened")
            logger.log_system_info(vmb)
            
            cameras = vmb.get_all_cameras()
            if not cameras:
                logger.warning("No cameras found")
                return
            
            logger.info(f"Selecting camera: {cameras[0].get_id()}")
            with cameras[0] as cam:
                logger.info("Camera opened")
                logger.log_camera_info(cam)
                
                # Configure camera
                logger.info("Configuring camera")
                try:
                    cam.set_pixel_format(vmbpy.PixelFormat.Bgr8)
                    logger.info("Pixel format set to Bgr8")
                except vmbpy.VmbFeatureError as e:
                    logger.error(f"Failed to set pixel format: {e}")
                
                # Get a single frame
                logger.info("Acquiring single frame")
                try:
                    frame = cam.get_frame()
                    logger.log_frame_info(frame)
                    logger.info("Frame acquired successfully")
                except vmbpy.VmbFrameError as e:
                    logger.error(f"Frame acquisition error: {e}")
                except vmbpy.VmbTimeout as e:
                    logger.error(f"Frame acquisition timeout: {e}")
                
                # Start streaming
                logger.info("Starting streaming mode")
                try:
                    cam.start_streaming(logger.frame_handler)
                    logger.info("Streaming for 10 seconds...")
                    time.sleep(10)
                    logger.info("Stopping streaming")
                    cam.stop_streaming()
                    logger.info("Streaming stopped")
                except Exception as e:
                    logger.error(f"Streaming error: {e}")
                
                logger.info("Camera session completed")
    
    except vmbpy.VmbSystemError as e:
        logger.critical(f"VmbSystem error: {e}")
    except Exception as e:
        logger.critical(f"Unexpected error: {e}")
    
    logger.info("Application exiting")

if __name__ == "__main__":
    main()
```

## 21. References and Resources

- VmbPy is developed by Allied Vision Technologies
- Documentation version: 1.1.0
- Additional resources can be found on the Allied Vision website
- Community forums and support are available through Allied Vision support channels

This documentation provides a comprehensive overview of the VmbPy API, with code examples and best practices for working with Allied Vision cameras. For the most up-to-date information, always refer to the official documentation and support resources provided by Allied Vision Technologies.